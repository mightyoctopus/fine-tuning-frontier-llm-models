{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53e0db04-5cef-4848-b39d-4f956af322be",
   "metadata": {},
   "source": [
    "# The Product Pricer With Linear Regression\n",
    "\n",
    "Traditional machine learning models that estimate how much a product costs based on extracted numeric features, such as weight, brand, text length, and popularity rank â€” rather than raw text descriptions.\n",
    "\n",
    "## Purpose\n",
    "\n",
    "To demonstrate a baseline regression model that can predict prices from structured data.\n",
    "This serves as the foundation to later compare and improve upon with more advanced models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5e17b7-71cd-4622-a27f-feaa834be52c",
   "metadata": {},
   "source": [
    "### Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1278affe-8f81-4ffa-94fc-0f0330a3c406",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas numpy scikit-learn gensim huggingface-hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daba92e6-a405-46e5-8533-9464f37879e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### General Imports\n",
    "import os\n",
    "import math\n",
    "import json\n",
    "import random\n",
    "from dotenv import load_dotenv\n",
    "import matplotlib.pyplot as plt \n",
    "import pickle \n",
    "from collections import Counter\n",
    "from huggingface_hub import login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb05f2ed-798a-486b-8689-d460e697b131",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imports For Traditional Machine Learning\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.linear_model import LinearRegression \n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7034c6-be93-441a-948f-732b32f303ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "### For NLP related machine learning\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d778493-87fc-4a09-b1ac-028c081fa58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### More of machine learning related ones\n",
    "from sklearn.svm import LinearSVR \n",
    "from sklearn.ensemble import RandomForestRegressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0770158d-349f-48c8-8974-e68777aae482",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Internal Classes\n",
    "\n",
    "from items import Item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073c063c-0a2e-4352-bc75-b5fb75c2c3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Constants -- used for printing to stdout in color\n",
    "\n",
    "GREEN = \"\\033[92m\"\n",
    "YELLOW = \"\\033[93m\"\n",
    "RED = \"\\033[91m\"\n",
    "RESET = \"\\033[0m\"\n",
    "COLOR_MAP = {\"green\": GREEN, \"orange\": YELLOW, \"red\": RED} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c275aecb-9975-4fba-be75-b12405ae7769",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Environment \n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "ANTHROPIC_API_KEY = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "HF_TOKEN_KEY = os.getenv(\"HF_TOKEN\")\n",
    "\n",
    "login(HF_TOKEN_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86831ba-acbb-4366-85dc-1ccd0cc2a669",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2f7e41-a7d2-4ba9-a923-2eb0f1d7e48d",
   "metadata": {},
   "source": [
    "## Loading the pkl files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22867221-0f12-4f2b-a358-107af44586f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train.pkl\", \"rb\") as f:\n",
    "    train = pickle.load(f)\n",
    "\n",
    "with open(\"test.pkl\", \"rb\") as f:\n",
    "    test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04cf26d-cffc-4d71-a9f6-b09ccf8b7080",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test[0].test_prompt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766ae325-88fd-4a04-a1b2-8b88750552dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test[0].price)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2980fe2-bf15-41bf-bcbf-3c10f7df1862",
   "metadata": {},
   "source": [
    "## Tester Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea1b2b2-9510-4f34-8547-350c1594c995",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tester: \n",
    "\n",
    "    def __init__(self, predictor, title=None, data=test, size=250): \n",
    "        self.predictor = predictor\n",
    "        self.data = data\n",
    "        ### Conditionally used for either the text report or chart's title\n",
    "        self.title = title or predictor.__name__.replace(\"_\", \" \").title()\n",
    "        self.size = size\n",
    "        self.truths = []\n",
    "        self.guesses = []\n",
    "        self.errors = []\n",
    "        self.sles = []\n",
    "        self.colors = []\n",
    "\n",
    "    def color_for(self, error, truth): \n",
    "        if error < 20 or error / truth < 0.2:\n",
    "            return \"green\"\n",
    "        elif error < 80 or error / truth < 0.4: \n",
    "            return \"orange\"\n",
    "        else:\n",
    "            return \"red\"\n",
    "\n",
    "    def run_datapoint(self, i): \n",
    "        datapoint = self.data[i]\n",
    "        guess = self.predictor(datapoint)\n",
    "        truth = datapoint.price\n",
    "        error = abs(guess - truth)\n",
    "        log_error = math.log(truth + 1) - math.log(guess + 1)\n",
    "        sle = log_error ** 2\n",
    "        color = self.color_for(error, truth)\n",
    "        title = datapoint.title if len(datapoint.title) < 40 else datapoint.title[:40] + \"...\"\n",
    "        self.truths.append(truth)\n",
    "        self.guesses.append(guess)\n",
    "        self.errors.append(error) \n",
    "        self.sles.append(sle) \n",
    "        self.colors.append(color) \n",
    "        print(f\"{COLOR_MAP[color]}{i + 1}: Guess: ${guess:,.2f} | Truth: ${truth:,.2f} | Error: {error:,.2f} | SLE: {sle:,.2f} Item: {title}{RESET}\")\n",
    "\n",
    "    def chart(self, title): \n",
    "        max_error = max(self.errors) \n",
    "        plt.figure(figsize=(12, 8))\n",
    "        max_val = max(max(self.truths), max(self.guesses))\n",
    "        plt.plot([0, max_val], [0, max_val], color=\"deepskyblue\", lw=2, alpha=0.6)\n",
    "        plt.scatter(self.truths, self.guesses, s=3, c=self.colors)\n",
    "        plt.xlabel('Ground Truth')\n",
    "        plt.ylabel('Model Estimate')\n",
    "        plt.xlim(0, max_val)\n",
    "        plt.ylim(0, max_val) \n",
    "        plt.title(title)\n",
    "        plt.show()\n",
    "\n",
    "    def report(self): \n",
    "        average_error = sum(self.errors) / self.size\n",
    "        rmsle = math.sqrt(sum(self.sles) / self.size)\n",
    "        hits = sum(1 for color in self.colors if color == \"green\")\n",
    "        title = f\"{self.title} Error=${average_error:,.2f} RMSLE={rmsle:,.2f} Hits={hits / self.size * 100:.1f}%\"\n",
    "        self.chart(title)\n",
    "\n",
    "    def run(self):\n",
    "        for i in range(self.size): \n",
    "            self.run_datapoint(i) \n",
    "        self.report()\n",
    "\n",
    "    @classmethod\n",
    "    def test(cls, function):\n",
    "        cls(function).run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea78b18-3cdb-414c-a69f-1a169cb718f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Simulator function\n",
    "\n",
    "def random_pricer(item): \n",
    "    return random.randrange(1, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d36267-bc5a-4cea-8505-af61766b1bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "\n",
    "### Run Tester with a simulating guess predictor\n",
    "Tester.test(random_pricer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc98aed-c29e-43c0-9376-8dd47f3f535f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Another test -- with average price from the train data\n",
    "\n",
    "training_prices = [item.price for item in train]\n",
    "training_avr_price = sum(training_prices) / len(training_prices)\n",
    "\n",
    "def constant_pricer(item): \n",
    "    return training_avr_price "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f6b380-946d-4583-8a59-909bb11007fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tester.test(constant_pricer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d4077e-e265-4b0e-b409-75895fb9d573",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Educational example using product weights, brand, and other fields \n",
    "to demonstrate feature engineering, not meant for real world usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d0ae4d-7ab7-4627-821f-9ad2e7147ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[0].details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd066412-d9f7-4478-a1c0-bf7eb55d1a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create a new \"features\" field on items, \n",
    "### and populate it with json parsed from the details dict\n",
    "\n",
    "for item in train: \n",
    "    item.features = json.loads(item.details)\n",
    "\n",
    "for item in test: \n",
    "    item.features = json.loads(item.details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5829c526-661f-4027-99a5-48ae0e3141c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train[0].features.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccce23c-b4fe-4fa7-9cd8-d19a5943a8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Look at 20 most common features in training set\n",
    "\n",
    "feature_count = Counter()\n",
    "\n",
    "for item in train: \n",
    "    for f in item.features.keys(): \n",
    "        feature_count[f] += 1\n",
    "\n",
    "feature_count.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35135bc-f45a-4cc8-b2de-168a875acf24",
   "metadata": {},
   "source": [
    "### Product Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb742a52-c1cd-4fa7-8142-3133ed4588bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some janky code to pluck out the Item Weight\n",
    "\n",
    "def get_weight(item):\n",
    "    weight_str = item.features.get('Item Weight')\n",
    "    if weight_str:\n",
    "        parts = weight_str.split(' ')\n",
    "        amount = float(parts[0])\n",
    "        unit = parts[1].lower()\n",
    "        if unit==\"pounds\":\n",
    "            return amount\n",
    "        elif unit==\"ounces\":\n",
    "            return amount / 16\n",
    "        elif unit==\"grams\":\n",
    "            return amount / 453.592\n",
    "        elif unit==\"milligrams\":\n",
    "            return amount / 453592\n",
    "        elif unit==\"kilograms\":\n",
    "            return amount / 0.453592\n",
    "        elif unit==\"hundredths\" and parts[2].lower()==\"pounds\":\n",
    "            return amount / 100\n",
    "        else:\n",
    "            print(weight_str)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcd0ba0-28d7-492d-b199-a07de31b79cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [get_weight(t) for t in test]\n",
    "\n",
    "### Filter out None values (if w)\n",
    "weights = [w for w in weights if w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599b8a3c-a2da-4659-8d84-1b38f2df4716",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_weight = sum(weights) / len(weights)\n",
    "print(f\"Avr Weight: {average_weight:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764f9824-fc78-435f-8da6-3a70482aba11",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set default weight for items with None value for weights\n",
    "def get_defualt_weight(item): \n",
    "    weight = get_weight(item)\n",
    "    return weight or average_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72915d53-9812-4f41-9e19-1e67fe106d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = get_weight(train[1000])\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6d514a-3257-4488-8276-9023d8401a3a",
   "metadata": {},
   "source": [
    "### Best Seller Ranks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb05726-539a-4d35-970e-8ab998aefc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rank(item): \n",
    "    \"\"\"\n",
    "    Get an average rank per item out of multiple ranks across different categories.\n",
    "    \"\"\"\n",
    "    ### A product has ranks across multiple categories in Amazon data\n",
    "    ranks_dict = item.features.get(\"Best Sellers Rank\")\n",
    "    if ranks_dict:\n",
    "        ranks = ranks_dict.values()\n",
    "        avr_rank = sum(ranks) / len(ranks)\n",
    "        return avr_rank\n",
    "        \n",
    "    return None\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848f7c74-2c68-4235-8d32-0f0c9f443fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_rank(train[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e141ab-2beb-4d52-bffb-83e1950e09e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = [get_rank(t) for t in train]\n",
    "ranks = [r for r in ranks if r]\n",
    "\n",
    "average_rank = sum(ranks) / len(ranks)\n",
    "print(f\"Average Rank = {average_rank:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c91d190-6d0a-414d-885b-eb98879933e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_rank(item): \n",
    "    rank = get_rank(item)\n",
    "    return rank or average_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6be3512-0992-49fb-a0cf-8ce8ce93e71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_length(item): \n",
    "    return len(item.prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8a37d2-ecb6-4091-a24f-4b399e0dba8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Look at 40 most common brands\n",
    "\n",
    "brand_counts = Counter()\n",
    "\n",
    "for t in train: \n",
    "    brand = t.features.get(\"Brand\")\n",
    "    if brand: \n",
    "        brand_counts[brand] += 1 \n",
    "\n",
    "print(brand_counts.most_common(40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea3e67c-1a47-4f56-88b2-6363d7d2f456",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP_ELECTRONICS_BRANDS = [\"hp\", \"dell\", \"lenovo\", \"samsung\", \"asus\", \"sony\", \"canon\", \"apple\", \"intel\"]\n",
    "\n",
    "def is_top_electronics_brand(item):\n",
    "    brand = item.features.get(\"Brand\")\n",
    "    return brand and brand.lower() in TOP_ELECTRONICS_BRANDS\n",
    "\n",
    "print(is_top_electronics_brand(train[2300]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d31358-f602-4a18-a393-291ea9172b23",
   "metadata": {},
   "source": [
    "### Result: get_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3753f891-d0bd-4f78-88c2-bd30da549942",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(item): \n",
    "    \"\"\"\n",
    "    Return weight, rank, text_length, and whether it's one of top electronics brands in a dictionary form\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"weight\": get_defualt_weight(item), \n",
    "        \"rank\": get_default_rank(item), \n",
    "        \"text_length\": get_text_length(item), \n",
    "        \"is_top_electronics_brand\": 1 if is_top_electronics_brand(item) else 0 \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f2a22f-d1fa-4df7-bf77-85e2264860f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_features(train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b372039-8a9b-4efc-9fde-7f226ce1879d",
   "metadata": {},
   "source": [
    "## Traditional Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639c2f74-d512-486d-b3d9-db53db59d974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A utility function to convert the features(dict) into a pandas dataframe\n",
    "\n",
    "def list_to_dataframe(items):\n",
    "    features = [get_features(item) for item in items]\n",
    "    df = pd.DataFrame(features)\n",
    "    ### Add price label\n",
    "    df[\"price\"] = [item.price for item in items]\n",
    "\n",
    "    return df\n",
    "\n",
    "train_df = list_to_dataframe(train)\n",
    "test_df = list_to_dataframe(test[:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afb4c39-3cc4-4997-8035-ba7aa19c598a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_df[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be626e1a-ecfd-4f51-96fc-c7fbe9564290",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Traditional Linear Regression\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "### Separate features and target \n",
    "feature_columns = [\"weight\", \"rank\", \"text_length\", \"is_top_electronics_brand\"]\n",
    "\n",
    "X_train = train_df[feature_columns]\n",
    "y_train = train_df[\"price\"]\n",
    "\n",
    "X_test = test_df[feature_columns]\n",
    "y_test = test_df[\"price\"]\n",
    "\n",
    "### Train a Linear Regression\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(model.coef_)\n",
    "\n",
    "### Print pairs of feature_columns and coefficients \n",
    "print(\"\\n|==Metrics Report==|\\n\")\n",
    "for features, coef in zip(feature_columns, model.coef_): \n",
    "    print(f\"{features}: {coef}\")\n",
    "\n",
    "### Intercept rate\n",
    "print(f\"Intercept: {model.intercept_}\")\n",
    "\n",
    "\n",
    "### Predict the test set and evaluate (with error metrics)\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squred Error: {mse}\")\n",
    "print(f\"R-Squared Score: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79518636-4e7f-440d-8b84-669a889b70c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function to predict price for a new item\n",
    "\n",
    "def linear_regression_pricer(item):\n",
    "    features = get_features(item)\n",
    "    print(\"FEATURES: \", features)\n",
    "    features_df = pd.DataFrame([features])\n",
    "    return model.predict(features_df)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d92f29c-a683-4bee-8e8f-43315d57e765",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tester.test(linear_regression_pricer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076e10fa-2a90-4825-bd9c-1d53e6f5545e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
