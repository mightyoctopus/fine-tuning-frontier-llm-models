{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10b9df47-6898-420b-8caa-ea29994512c5",
   "metadata": {},
   "source": [
    "# The Product Pricer Continued\n",
    "\n",
    "A model that can estimate how much something costs, from its description.\n",
    "\n",
    "## Enter a Couple of Frontier Models:\n",
    "\n",
    "And now - putting some Frontier Models to the test.\n",
    "\n",
    "### 2 important points:\n",
    "\n",
    "It's important to appreciate that any actual training on the frontier models won't be done in this notebook section. But what's done will be just providing them with the Test dataset to see how they perform. They don't gain the benefit of the 400,000 training examples that we provided to the Traditional ML models.\n",
    "\n",
    "HAVING SAID THAT...\n",
    "\n",
    "It's entirely possible that in their monstrously large training data, they've already been exposed to all the products in the training AND the test set. So there could be test \"contamination\" here which gives them an unfair advantage which is good to keep in mind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6258e5a0-2605-46cb-b98b-86f765d8bfbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import re\n",
    "import math \n",
    "import json \n",
    "import random \n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import login \n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "import pickle\n",
    "from collections import Counter\n",
    "\n",
    "### Frontier models:\n",
    "from openai import OpenAI \n",
    "from anthropic import Anthropic \n",
    "\n",
    "### Internal classes: \n",
    "from items import Item \n",
    "from testing import Tester "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c43edfc-171c-41d3-a15f-596968662cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "### Environment \n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "ANTHROPIC_API_KEY = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "HF_TOKEN = os.getenv(\"HF_TOKEN\")\n",
    "\n",
    "login(HF_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d84eb45-278e-4aa1-9594-43570b91b7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_client = OpenAI() \n",
    "claude_client = Anthropic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "feaee48d-6790-442f-b1cd-0af6502ee5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8a26e88-5c99-45a0-9514-defbacbf61a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load pickle files of datasets: \n",
    "\n",
    "with open(\"train.pkl\", \"rb\") as f: \n",
    "    train = pickle.load(f)\n",
    "\n",
    "with open(\"test.pkl\", \"rb\") as f: \n",
    "    test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccc3720-ca55-4abb-aad1-685f289b3308",
   "metadata": {},
   "source": [
    "## Human Prediction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1d3026a-c407-4753-aa09-338ef049fb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Write the test set to a CSV\n",
    "\n",
    "import csv \n",
    "\n",
    "with open(\"human_input.csv\", \"w\") as f: \n",
    "    writer = csv.writer(f)\n",
    "    for t in test[:250]: \n",
    "        writer.writerow([t.test_prompt(), 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e67d269-6682-4373-ad94-327c4c22b8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read it back in and manually fill in the price column with (human) price guesses\n",
    "### And then, move each guesses price into human_predictions which will be used, aligned with \n",
    "### the human_pricer function (price generator function)\n",
    "\n",
    "human_predictions = []\n",
    "\n",
    "with open(\"human_output.csv\", \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "\n",
    "    for row in reader:\n",
    "        human_predictions.append(float(row[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a604643-3528-406b-8bba-8b73e758c171",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def human_pricer(item): \n",
    "    idx = test.index(item)\n",
    "    print(\"IDX: \", idx)\n",
    "    return human_predictions[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49972c5a-8979-4a77-81ad-a7a7dad2a7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tester.test(human_pricer, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e192c5cb-66bb-4884-9512-3ff6c8a546f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How much does this cost?\\n\\nSydney Rustic Mirror - Vanity Mirror, Bathroom Mirror, Farmhouse Decor, Wood Mirror, Large Mirror - 4 Sizes & 20 Colors - Red Oak\\nThe Sydney low profile thin wood framed mirror will blend effortlessly in your current decor creating a simple yet sophisticated look. Our mirror features a reclaimed rustic styled wood finish, strong decorative lines with a thin 2.25â€ inch wide frame maximizing the visible mirror. This hanging mirror can be mounted horizontally or vertically. Available in 20 Colors - Shown in Red Oak. Not sure on color we do color samples please contact us for details. Available in 4 sizes, 24x30, 36x30, 42x30 & 60x30, all measurements are overall dimensions including frame and mirror. We offer two types\\n\\n'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[0].test_prompt().replace(\" to the nearest dollar\", \"\").replace(\"Price is $\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38526724-3207-4f94-98c1-30ffcf4d8a43",
   "metadata": {},
   "source": [
    "## GPT-4o-mini Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3577d945-3bc9-4e82-850c-de1948dfa561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip out phrases such as:\n",
    "# 1. to the nearest dollar\n",
    "# 2. Price is $\n",
    "### Reason: Now integrating with a GPT 5 model which is sophisticated enough \n",
    "### to handle it and understand without such guardrails \n",
    "\n",
    "def messages_for(item): \n",
    "    system_message = \"You estimate the price of item. Reply only with the price without any additional explanation or comment.\"\n",
    "    user_prompt = item.test_prompt().replace(\" to the nearest dollar\", \"\").replace(\"Price is $\", \"\")\n",
    "\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_message}, \n",
    "        {\"role\": \"user\", \"content\": user_prompt}, \n",
    "        {\"role\": \"assistant\", \"content\": \"Price is $\"} # little trick to encourage the response followed in this form\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a0e9e1-265d-44f5-9162-b784fdcaa93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages_for(test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6cdb4be3-a6ed-49da-8867-01d5ea59e365",
   "metadata": {},
   "outputs": [],
   "source": [
    "### a utility function that extracts the price (float) \n",
    "### out of LLM's responses\n",
    "\n",
    "def get_price(s: str): \n",
    "    s = s.replace(\"$\", \"\").replace(\",\", \"\")\n",
    "    match = re.search(r\"[-+]?\\d*\\.\\d+|\\d+\", s)\n",
    "    return float(match.group()) if match else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "74387fb7-442c-4a9a-9c09-b49bfe81e165",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'continue' not properly in loop (4070876250.py, line 12)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mcontinue\u001b[39m\n    ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m 'continue' not properly in loop\n"
     ]
    }
   ],
   "source": [
    "def gpt_5_pricer(item): \n",
    "    try:\n",
    "        completion = openai_client.chat.completions.create(\n",
    "            model=\"gpt-5-mini\", \n",
    "            messages=messages_for(item)\n",
    "        )\n",
    "        response = completion.choices[0].message.content\n",
    "        \n",
    "        return get_price(response)\n",
    "    except Exception as e: \n",
    "        print({e})\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2303bb5-b1a6-4498-ac41-283a45b49c2d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gpt_5_pricer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m Tester.test(\u001b[43mgpt_5_pricer\u001b[49m, test)\n",
      "\u001b[31mNameError\u001b[39m: name 'gpt_5_pricer' is not defined"
     ]
    }
   ],
   "source": [
    "Tester.test(gpt_5_pricer, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fec47585-b6e5-4c02-ae18-956fcac75117",
   "metadata": {},
   "outputs": [],
   "source": [
    "def claude_haiku_pricer(item): \n",
    "    messages = messages_for(item)\n",
    "    system_message = messages[0][\"content\"]\n",
    "    messages = messages[1:]\n",
    "    completion = claude_client.messages.create(\n",
    "        model=\"claude-3-5-haiku-latest\", \n",
    "        max_tokens=5, \n",
    "        system=system_message, \n",
    "        messages=messages\n",
    "    )\n",
    "    response = completion.content[0].text \n",
    "    return get_price(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ae153c-0265-4cfb-b7bc-bb728dc6de84",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tester.test(claude_haiku_pricer, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b0d09608-15ae-4144-8c8c-0df11ae2571a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gpt_5_pricer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m Tester.test(\u001b[43mgpt_5_pricer\u001b[49m, test[\u001b[32m0\u001b[39m])\n",
      "\u001b[31mNameError\u001b[39m: name 'gpt_5_pricer' is not defined"
     ]
    }
   ],
   "source": [
    "Tester.test(gpt_5_pricer, test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f0cdef1d-1725-4d03-9dbc-0b53dfba3502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "189.99"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[0].price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7a0103-4731-461a-aa74-ae4ff9bb160f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
