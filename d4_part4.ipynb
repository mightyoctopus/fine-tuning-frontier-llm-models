{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10b9df47-6898-420b-8caa-ea29994512c5",
   "metadata": {},
   "source": [
    "# The Product Pricer Continued\n",
    "\n",
    "A model that can estimate how much something costs, from its description.\n",
    "\n",
    "## Enter The Frontier!\n",
    "\n",
    "And now - putting some Frontier Models to the test.\n",
    "\n",
    "### 2 important points:\n",
    "\n",
    "It's important to appreciate that any actual training on the frontier models won't be done in this notebook section. But what's done will be just providing them with the Test dataset to see how they perform. They don't gain the benefit of the 400,000 training examples that we provided to the Traditional ML models.\n",
    "\n",
    "HAVING SAID THAT...\n",
    "\n",
    "It's entirely possible that in their monstrously large training data, they've already been exposed to all the products in the training AND the test set. So there could be test \"contamination\" here which gives them an unfair advantage which is good to keep in mind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6258e5a0-2605-46cb-b98b-86f765d8bfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import re\n",
    "import math \n",
    "import json \n",
    "import random \n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import login \n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "import pickle\n",
    "from collections import Counter\n",
    "\n",
    "### Frontier models:\n",
    "from openai import OpenAI \n",
    "from anthropic import Anthropic \n",
    "\n",
    "### Internal classes: \n",
    "from items import Item \n",
    "from testing import Tester "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c43edfc-171c-41d3-a15f-596968662cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "### Environment \n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "ANTHROPIC_API_KEY = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "HF_TOKEN = os.getenv(\"HF_TOKEN\")\n",
    "\n",
    "login(HF_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d84eb45-278e-4aa1-9594-43570b91b7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_client = OpenAI() \n",
    "claude_client = Anthropic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "feaee48d-6790-442f-b1cd-0af6502ee5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8a26e88-5c99-45a0-9514-defbacbf61a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load pickle files of datasets: \n",
    "\n",
    "with open(\"train.pkl\", \"rb\") as f: \n",
    "    train = pickle.load(f)\n",
    "\n",
    "with open(\"test.pkl\", \"rb\") as f: \n",
    "    test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccc3720-ca55-4abb-aad1-685f289b3308",
   "metadata": {},
   "source": [
    "## Human Prediction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1d3026a-c407-4753-aa09-338ef049fb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Write the test set to a CSV \n",
    "\n",
    "import csv \n",
    "\n",
    "with open(\"human_input.csv\", \"w\") as f: \n",
    "    writer = csv.writer(f)\n",
    "    for t in test[:250]: \n",
    "        writer.writerow([t.test_prompt(), 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2e67d269-6682-4373-ad94-327c4c22b8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read it back in\n",
    "\n",
    "human_predictions = []\n",
    "\n",
    "with open(\"human_output.csv\", \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "\n",
    "    for row in reader:\n",
    "        human_predictions.append(float(row[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4a604643-3528-406b-8bba-8b73e758c171",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def human_pricer(item): \n",
    "    idx = test.index(item)\n",
    "    print(\"IDX: \", idx)\n",
    "    return human_predictions[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49972c5a-8979-4a77-81ad-a7a7dad2a7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tester.test(human_pricer, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e192c5cb-66bb-4884-9512-3ff6c8a546f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
